{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE \n",
    "\n",
    "For practical implementation:\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html\n",
    "\n",
    "For theoretical knowledge of spline:\n",
    "https://timodenk.com/blog/cubic-spline-interpolation/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Mathieu Blondel\n",
    "#         Jake Vanderplas\n",
    "#         Christian Lorentzen\n",
    "#         Malte Londschien\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial on Day-ahead data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is going to happen is as follows:\n",
    "\n",
    "0. Try to plot day-ahead price\n",
    "1. Try fit a periodic spline on day-ahead data\n",
    "2. Pick 5 spots on the day-ahead price and add noise to it. Then fit a periodic spline function to it afterwards"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the real.csv file and the day-ahead"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 90)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('real.csv') # Change path\n",
    "data = data.fillna(0)\n",
    "spot = data[\"Spot\"].to_numpy()\n",
    "spot_reshape = np.reshape(spot, (24, 90+365),order ='F') # F to ensure the correct reshaping.\n",
    "spot_reshaped_forecasted = spot_reshape[:,365:]\n",
    "mean_spot_all_days = np.mean(spot_reshaped_forecasted,axis=1)\n",
    "std_spot_all_days = np.std(spot_reshaped_forecasted,axis = 1)\n",
    "\n",
    "\n",
    "print(np.shape(spot_reshape[:,365:]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([0,3,8,13,18,23])\n",
    "y_train = mean_spot_all_days[x_train]\n",
    "plt.plot(mean_spot_all_days)\n",
    "plt.scatter(x_train, y_train,c='black', label=\"training points\")\n",
    "plt.ylabel(\"Price [EUR]\")\n",
    "\n",
    "# Set the plot title\n",
    "title = \"Mean Spot price \"\n",
    "plt.title(title, fontsize=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate with spline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([0,3,8,13,18,23]) # Data which is traded upon\n",
    "X_train = x_train[:, np.newaxis] # necessary for the scikit method to work\n",
    "y_train = spot_reshaped_forecasted[x_train,1]\n",
    "\n",
    "x_plot = np.arange(24) # For plotting purposes\n",
    "X_plot = x_plot[:, np.newaxis]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = make_pipeline(SplineTransformer(n_knots=6, degree=3), Ridge(alpha=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_plot = model.predict(X_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spot_reshaped_forecasted[:,1],label = \"Day-ahead price\")\n",
    "plt.plot(y_plot,label = \"Forecast - No noise\")\n",
    "plt.scatter(x_train, y_train,c='black', label=\"training points\")\n",
    "plt.legend(loc=\"lower center\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING NOISE TO CREATE THE FORECASTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we assess the standard deviation of the time instances of our data, because then we know how much noise we should add.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.reshape(std_spot_all_days[x_train],(6,1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the standard deviation is way too much, so let us take a percentage of it. For\n",
    "\n",
    "- D-2, 30 %\n",
    "- DA, 20 %\n",
    "- D-1, 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_train = std_spot_all_days[x_train]*0.1\n",
    "noise = np.random.normal(0, std_train, std_train.shape)\n",
    "print(np.shape(noise))\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forecast_of_spot(Spot_data):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    Spot_data (dataframe). NEED TO BE DIVISIBLE OF 24\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Load the data\n",
    "    spot = Spot_data.to_numpy() # Transform to numpy\n",
    "    spot_reshape = np.reshape(spot, (24, int(len(spot)/24)),order ='F') # F to ensure the correct reshaping\n",
    "    mean_spot_all_days = np.mean(spot_reshape,axis=1)\n",
    "    std_spot_all_days  = np.std(spot_reshape  ,axis = 1)\n",
    "\n",
    "    # Set the training data settings\n",
    "    x_train = np.array([0,3,8,13,18,23]) # Data which is traded upon\n",
    "    X_train = x_train[:, np.newaxis] # necessary for the scikit method to work\n",
    "\n",
    "    # Construct the noise\n",
    "    std_train_D_2 = std_spot_all_days[x_train]*0.2\n",
    "    std_train_D_1 = std_spot_all_days[x_train]*0.1\n",
    "    noise_D_2 = np.random.normal(0, std_train_D_2, std_train_D_2.shape)\n",
    "    noise_D_1 = np.random.normal(0, std_train_D_1, std_train_D_1.shape)\n",
    "\n",
    "    # Set up the calculated parts\n",
    "    True_Spot= spot_reshape \n",
    "    Forecast_no_noise = np.zeros((24,90))\n",
    "    Forecast_D_2 = np.zeros((24,90))\n",
    "    Forecast_D_1 = np.zeros((24,90))\n",
    "\n",
    "\n",
    " \n",
    "   # Set up settings for the Spline interpolation\n",
    "    x_day = np.arange(24) # For plotting purposes\n",
    "    X_day = x_day[:, np.newaxis]\n",
    "\n",
    "    model = make_pipeline(SplineTransformer(n_knots=6, degree=3), Ridge(alpha=1e-3))\n",
    "\n",
    "    days = len(True_Spot[0,:])\n",
    "    for d in range(0,days):\n",
    "\n",
    "        # Forecast with noise, at D-2. Two days prior\n",
    "        y_train_D_2 = True_Spot[x_train,d] + noise_D_2\n",
    "        model.fit(X_train, y_train_D_2) \n",
    "        y_day = model.predict(X_day) \n",
    "        Forecast_D_2[:,d] = np.reshape(y_day, (24,) ) # Save the forecast\n",
    "\n",
    "        # Forecast with noise, at D-1. One days prior\n",
    "        y_train_D_1 = True_Spot[x_train,d] + noise_D_1\n",
    "        model.fit(X_train, y_train_D_1) \n",
    "        y_day = model.predict(X_day) \n",
    "        Forecast_D_1[:,d] = np.reshape(y_day, (24,) ) # Save the forecast\n",
    "\n",
    "        # Forecast without noise\n",
    "        model.fit(X_train, spot_reshape[x_train,d]) \n",
    "        y_day = model.predict(X_day)\n",
    "        Forecast_no_noise[:,d] = np.reshape(y_day, (24,) ) # Save the forecast\n",
    "\n",
    "\n",
    "    \n",
    "    return Forecast_D_2, Forecast_D_1, Forecast_no_noise, True_Spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forecast_D_2, Forecast_D_1, Forecast_no_noise, True_Spot = Forecast_of_spot(data[\"Spot\"].loc[(24*365):])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the font size of the plot\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "# Set the figure size and dpi\n",
    "fig = plt.figure(figsize=(8, 6), dpi=100)\n",
    "\n",
    "# Plot the data\n",
    "d = 10\n",
    "plt.plot(True_Spot[:,d],  label=\"Day-ahead price\")\n",
    "plt.plot(Forecast_D_2[:,d],  label=\"Forecast 2 days prior\")\n",
    "plt.plot(Forecast_D_1[:,d],  label=\"Forecast 1 day prior\")\n",
    "plt.scatter(x_train, Forecast_D_2[x_train,d], c='black', s=10)\n",
    "plt.scatter(x_train, Forecast_D_1[x_train,d], c='black', s=10)\n",
    "\n",
    "# Add a legend outside of the plots\n",
    "fig.legend(loc='lower center', bbox_to_anchor=(0.5, -0.001), ncol=3)\n",
    "\n",
    "plt.ylabel(\"Price [EUR]\")\n",
    "\n",
    "# Set the plot title\n",
    "title = \"Spot price and forecast at day {}\".format(d)\n",
    "plt.title(title, fontsize=18)\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.savefig('Spot_Forecast.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "avg_percentage = np.mean(np.abs(True_Spot - Forecast_D_2) / True_Spot, axis=0)\n",
    "print(np.mean(avg_percentage))\n",
    "avg_percentage = np.mean(np.abs(True_Spot - Forecast_D_1) / True_Spot, axis=0)\n",
    "print(np.mean(avg_percentage))\n",
    "for d, avg in enumerate(avg_percentage):\n",
    "    print(\"Day\", d, avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the font size of the plot\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "# Set the figure size and dpi\n",
    "fig = plt.figure(figsize=(8, 6), dpi=100)\n",
    "\n",
    "# Plot the data\n",
    "d = 0\n",
    "plt.plot(True_Spot[:,d],  label=\"Day-ahead price\")\n",
    "plt.plot(Forecast_D_2[:,d],  label=\"Forecast 2 days prior\")\n",
    "plt.plot(Forecast_D_1[:,d],  label=\"Forecast 1 day prior\")\n",
    "plt.scatter(x_train, Forecast_D_2[x_train,d], c='black', s=10)\n",
    "plt.scatter(x_train, Forecast_D_1[x_train,d], c='black', s=10)\n",
    "\n",
    "# Add a legend outside of the plots\n",
    "fig.legend(loc='lower center', bbox_to_anchor=(0.5, -0.001), ncol=3)\n",
    "\n",
    "plt.ylabel(\"Price [EUR]\")\n",
    "\n",
    "# Set the plot title\n",
    "title = \"Spot price and forecast at day {}\".format(d)\n",
    "plt.title(title, fontsize=18)\n",
    "\n",
    "# Show the plot\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it all into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Spot_reshaped = pd.DataFrame(np.reshape(True_Spot, (24*90,), order = 'F'),columns=[\"Spot\"])\n",
    "\n",
    "Forecast_D_2_reshaped = pd.DataFrame(np.reshape(Forecast_D_2, (24*90,), order = 'F'),columns=[\"Spot_D_2\"])\n",
    "Forecast_D_1_reshaped = pd.DataFrame(np.reshape(Forecast_D_1, (24*90,), order = 'F'),columns=[\"Spot_D_1\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up FCR-D forecast. Mean for the past 5 days.\n",
    "- At D-2 it is past 5 days, meaning 7 days from what to predict.\n",
    "- At D-1 it is the past 5 days, meaning 6 days from what to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('real.csv') # Change path\n",
    "data = data.fillna(0) \n",
    "data_cop = data.copy()\n",
    "data = data.drop(columns=[\"Hour\"])\n",
    "setup_forecast = data_cop.drop(columns=[\"Hour\"])\n",
    "True_data = data.loc[8760:].reset_index(drop=True)\n",
    "True_data.columns\n",
    "Spot_data = True_data['Spot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Spot', 'FD1_down', 'FD2_down', 'FD1_up', 'FD2_up', 'FD1_up_percentage',\n",
      "       'FD2_up_percentage', 'FD1_down_percentage', 'FD2_down_percentage',\n",
      "       'FD_act_up', 'FD_act_down'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Total_length_test = len(data[\"FD1_down\"]) - 8760\n",
    "# Create an empty dataframe with the same columns as `data`\n",
    "forecasted_data_D_2 = pd.DataFrame(columns=setup_forecast.columns, index=range(Total_length_test))\n",
    "forecasted_data_D_1 = pd.DataFrame(columns=setup_forecast.columns, index=range(Total_length_test))\n",
    "True_data = pd.DataFrame(columns=setup_forecast.columns, index=range(Total_length_test))\n",
    "\n",
    "print(forecasted_data_D_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot started\n",
      "Spot ended\n"
     ]
    }
   ],
   "source": [
    "\n",
    "D_2_list = 24*[3,4,5,6,7]\n",
    "D_1_list = 24*[2,3,4,5,6]\n",
    "for col in data.columns:\n",
    "    if col == \"Spot\":\n",
    "        # Run spline procedure\n",
    "        # Use True_data\n",
    "        print(\"Spot started\")\n",
    "        Forecast_Spot_D_2, Forecast_Spot_D_1, Forecast_Spot_no_noise, True_Spot = Forecast_of_spot(Spot_data)\n",
    "        Forecast_D_2_reshaped = pd.DataFrame(np.reshape(Forecast_Spot_D_2, (24*90,), order = 'F'),columns=[\"Spot\"])\n",
    "        forecasted_data_D_2[col] = Forecast_D_2_reshaped\n",
    "        Forecast_D_1_reshaped = pd.DataFrame(np.reshape(Forecast_Spot_D_1, (24*90,), order = 'F'),columns=[\"Spot\"] )\n",
    "        forecasted_data_D_1[col] = Forecast_D_1_reshaped\n",
    "        True_Spot_reshaped = pd.DataFrame(np.reshape(True_Spot, (24*90,), order = 'F'),columns=[\"Spot\"] )\n",
    "        True_data = True_Spot_reshaped\n",
    "        print(\"Spot ended\")\n",
    "    else: \n",
    "        print(col, \" started\")\n",
    "        # Run mean procedure\n",
    "        for h in range(0,Total_length_test):\n",
    "            True_data.loc[h, col] = data.loc[h+8760,col]\n",
    "            # As the volumes need to add up to 100% then is it only the D-1 which has been forecasted as t\n",
    "            if 'percentage' in col:\n",
    "                if \"FD2\" in col:\n",
    "                    if \"up\" in col:\n",
    "                        forecasted_data_D_2.loc[h, col] = 1 - forecasted_data_D_2.loc[h, 'FD1_up_percentage']\n",
    "                        forecasted_data_D_1.loc[h, col] = 1 - forecasted_data_D_1.loc[h, 'FD1_up_percentage']\n",
    "                    else:\n",
    "                        forecasted_data_D_2.loc[h, col] = 1 - forecasted_data_D_2.loc[h, 'FD1_down_percentage']\n",
    "                        forecasted_data_D_1.loc[h, col] = 1 - forecasted_data_D_1.loc[h, 'FD1_down_percentage']\n",
    "                else:\n",
    "                    forecasted_data_D_2.loc[h, col] = np.mean([data.loc[h+8760-hd, col] for hd in D_2_list])\n",
    "                    forecasted_data_D_1.loc[h, col] = np.mean([data.loc[h+8760-hd, col] for hd in D_1_list])\n",
    "\n",
    "            else:\n",
    "                forecasted_data_D_2.loc[h, col] = np.mean([data.loc[h+8760-hd, col] for hd in D_2_list])\n",
    "                forecasted_data_D_1.loc[h, col] = np.mean([data.loc[h+8760-hd, col] for hd in D_1_list])\n",
    "                \n",
    "        print(col, \" ended\")\n",
    "\n",
    "                \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify the predictability of the forecasts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a histogram of the precision\n",
    "Remove all true values which are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot\n",
      "[-12.07487191  -7.86830604  -1.59208672 ...  66.47764887  40.68190022\n",
      "  21.14811114]\n",
      "0.5321396943595096\n",
      "FD1_down\n",
      "[323.5532579999999 336.005888 274.50441799999993 ... 11.633944000000001\n",
      " 10.740552000000001 9.770456000000001]\n",
      "inf\n",
      "FD2_down\n",
      "[53.08922 55.571813999999996 58.03772000000001 ... 18.223052\n",
      " 18.242701999999998 18.243099999999995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel  BV\\AppData\\Local\\Temp\\ipykernel_25752\\1798536061.py:13: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  avg_percentage = np.mean(np.abs(true - pred) / true)\n",
      "C:\\Users\\Daniel  BV\\AppData\\Local\\Temp\\ipykernel_25752\\1798536061.py:14: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  Percentage_data[col] = np.abs(true - pred) / true\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (2158) does not match length of index (2160)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m     true \u001b[39m=\u001b[39m True_data[col]\u001b[39m.\u001b[39mloc[indexes]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     13\u001b[0m     avg_percentage \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mabs(true \u001b[39m-\u001b[39m pred) \u001b[39m/\u001b[39m true)\n\u001b[1;32m---> 14\u001b[0m     Percentage_data[col] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(true \u001b[39m-\u001b[39m pred) \u001b[39m/\u001b[39m true\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(avg_percentage)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Assuming avg_percentage is your array\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m#masked_avg_percentage = avg_percentage[np.logical_and(np.isfinite(avg_percentage), ~np.isnan(avg_percentage))]\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m#mean = np.mean(masked_avg_percentage)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[39m#print(mean)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel  BV\\Desktop\\Thesis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\Daniel  BV\\Desktop\\Thesis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4172\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4174\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4177\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4178\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4179\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4180\u001b[0m     ):\n\u001b[0;32m   4181\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4182\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\Daniel  BV\\Desktop\\Thesis\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4914\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4915\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4916\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel  BV\\Desktop\\Thesis\\.venv\\lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (2158) does not match length of index (2160)"
     ]
    }
   ],
   "source": [
    "Percentage_data = pd.DataFrame(columns=['Spot', 'FD1_down', 'FD2_down', 'FD1_up', 'FD2_up'], index=range(Total_length_test))\n",
    "\n",
    "for col in ['Spot', 'FD1_down', 'FD2_down', 'FD1_up', 'FD2_up']:\n",
    "    print(col)\n",
    "    # why inf.....\n",
    "    indexes = np.where(true != 0)[0] # Index to NOT remove\n",
    "\n",
    "    pred = forecasted_data_D_2[col].loc[indexes].values\n",
    "    print(pred)\n",
    "    true = True_data[col].loc[indexes].values\n",
    "\n",
    "\n",
    "    avg_percentage = np.mean(np.abs(true - pred) / true)\n",
    "    Percentage_data[col] = np.abs(true - pred) / true\n",
    "    print(avg_percentage)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming avg_percentage is your array\n",
    "#masked_avg_percentage = avg_percentage[np.logical_and(np.isfinite(avg_percentage), ~np.isnan(avg_percentage))]\n",
    "#mean = np.mean(masked_avg_percentage)\n",
    "\n",
    "#print(mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_FCRD_vol = data[[\"FD1_down_percentage\",\"FD2_down_percentage\",\"FD1_up_percentage\",\"FD2_up_percentage\"]].loc[8760:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8), dpi=100)\n",
    "d = 10\n",
    "for i, col in enumerate(True_FCRD_vol.columns):\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    ax.plot(True_FCRD_vol[col].iloc[int(0+float(d)*24):int(24+float(d)*24)]*100, label=\"True FCR-D volumes\")\n",
    "    ax.plot(forecasted_data_D_2[col].iloc[int(0+float(d)*24):int(24+float(d)*24)]*100, label=\"Forecast 2 days prior\")\n",
    "    ax.plot(forecasted_data_D_1[col].iloc[int(0+float(d)*24):int(24+float(d)*24)]*100, label=\"Forecast 1 day prior\")\n",
    "    ax.set_ylabel(col)\n",
    "\n",
    "axs[0,0].set_ylabel('D-1 up Volume [%]') \n",
    "axs[0,1].set_ylabel('D-2 up Volume [%]') \n",
    "axs[1,0].set_ylabel('D-1 dn Volume [%]') \n",
    "axs[1,1].set_ylabel('D-2 dn Volume [%]') \n",
    "\n",
    "\n",
    "# Add a legend outside of the plots\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.001), ncol=3)\n",
    "\n",
    "# Set the plot title\n",
    "title = \"FCR-D Volumes and forecast at day {}\".format(d)\n",
    "fig.suptitle(title, fontsize=18)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "fig.savefig('FCR-D_Forcasts_volumes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Sample data\n",
    "data = df[\"Spot\"]\n",
    "\n",
    "# Set up seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create histogram\n",
    "sns.histplot(data, kde=True, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Occurences')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_FCRD = data[[\"FD1_down\",\"FD2_down\",\"FD1_up\",\"FD2_up\"]].loc[8760:].reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8), dpi=100)\n",
    "d = 10\n",
    "for i, col in enumerate(True_FCRD.columns):\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    ax.plot(True_FCRD[col].iloc[int(0+float(d)*24):int(24+float(d)*24)], label=\"True FCR-D prices\")\n",
    "    ax.plot(forecasted_data_D_2[col].iloc[int(0+float(d)*24):int(24+float(d)*24)], label=\"Forecast 2 days prior\")\n",
    "    ax.plot(forecasted_data_D_1[col].iloc[int(0+float(d)*24):int(24+float(d)*24)], label=\"Forecast 1 day prior\")\n",
    "    ax.set_ylabel(col)\n",
    "\n",
    "axs[0,0].set_ylabel('D-1 up price [EUR/MW]') \n",
    "axs[0,1].set_ylabel('D-2 up price [EUR/MW]') \n",
    "axs[1,0].set_ylabel('D-1 dn price [EUR/MW]') \n",
    "axs[1,1].set_ylabel('D-2 dn price [EUR/MW]') \n",
    "\n",
    "\n",
    "# Add a legend outside of the plots\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.001), ncol=3)\n",
    "\n",
    "# Set the plot title\n",
    "title = \"FCR-D prices and forecast at day {}\".format(d)\n",
    "fig.suptitle(title, fontsize=18)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "fig.savefig('FCR-D_Forcasts_prices.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_act = data[[\"FD_act_up\",\"FD_act_down\"]].loc[8760:].reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8), dpi=100)\n",
    "d = 10\n",
    "for i, col in enumerate(True_act.columns):\n",
    "    ax = axs[i]\n",
    "    ax.plot(True_act[col].iloc[int(0+float(d)*24):int(24+float(d)*24)], label=\"True activation\")\n",
    "    ax.plot(forecasted_data_D_2[col].iloc[int(0+float(d)*24):int(24+float(d)*24)], label=\"Forecast 2 days prior\")\n",
    "    ax.plot(forecasted_data_D_1[col].iloc[int(0+float(d)*24):int(24+float(d)*24)], label=\"Forecast 1 day prior\")\n",
    "    ax.set_ylabel(col)\n",
    "\n",
    "axs[0].set_ylabel('D-1 up price [EUR/MW]')  \n",
    "axs[1].set_ylabel('D-1 dn price [EUR/MW]')\n",
    "\n",
    "\n",
    "# Add a legend outside of the plots\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.001), ncol=3)\n",
    "\n",
    "# Set the plot title\n",
    "title = \"Activation and forecast at day {}\".format(d)\n",
    "fig.suptitle(title, fontsize=18)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "fig.savefig('Activation_Forecasts.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a csv file for forecasted values of D-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecasted_data_D_2 = forecasted_data_D_2\n",
    "Forecast_Spot_D_2_reshaped = pd.DataFrame(np.reshape(Forecast_Spot_D_2, (24*90,), order = 'F'),columns=[\"Spot\"])\n",
    "print(forecasted_data_D_2.columns)\n",
    "print(Forecast_Spot_D_2_reshaped.columns)\n",
    "forecast_D_2_comb = pd.concat([Forecast_Spot_D_2_reshaped, forecasted_data_D_2], axis=1)\n",
    "print(forecast_D_2_comb.shape)\n",
    "print(forecast_D_2_comb.columns)\n",
    "\n",
    "#Create csv\n",
    "forecast_D_2_comb.to_csv(\"forecast.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
